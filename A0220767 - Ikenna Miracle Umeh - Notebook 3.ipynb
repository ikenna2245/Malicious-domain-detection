{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7bf0ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.post1.tar.gz (3.6 kB)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py): started\n",
      "  Building wheel for sklearn (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2343 sha256=a3d098548908faf2ac457861c14b9c13783d48e22c4f61de604ba519e2ff539d\n",
      "  Stored in directory: c:\\users\\ikenn\\appdata\\local\\pip\\cache\\wheels\\14\\25\\f7\\1cc0956978ae479e75140219088deb7a36f60459df242b1a72\n",
      "Successfully built sklearn\n",
      "Installing collected packages: sklearn\n",
      "Successfully installed sklearn-0.0.post1\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "77b1d302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdf9ea08",
   "metadata": {},
   "outputs": [],
   "source": [
    "urldata = pd.read_csv('urldata_nlp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fae18fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "urldata = urldata.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b506ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>malicious</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>malicious</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>malicious</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090222</th>\n",
       "      <td>malicious</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090223</th>\n",
       "      <td>malicious</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090224</th>\n",
       "      <td>malicious</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090225</th>\n",
       "      <td>malicious</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090226</th>\n",
       "      <td>malicious</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1090227 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              type  target\n",
       "0        malicious       1\n",
       "1           benign       0\n",
       "2           benign       0\n",
       "3        malicious       1\n",
       "4        malicious       1\n",
       "...            ...     ...\n",
       "1090222  malicious       1\n",
       "1090223  malicious       1\n",
       "1090224  malicious       1\n",
       "1090225  malicious       1\n",
       "1090226  malicious       1\n",
       "\n",
       "[1090227 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def type_encoder(x):\n",
    "    if x == 'malicious':\n",
    "        return 1\n",
    "    elif x == 'benign':\n",
    "        return 0\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "urldata['target'] = urldata['type'].apply(lambda x: type_encoder(x))\n",
    "\n",
    "urldata[['type', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89df6c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ['https', 'digits', 'letters','url_len','len_subdomain','is_subdomain', 'ratioUrlDomLen',  'count_spl', \n",
    "                'ratioSpltinurl','Shortining_Service', 'having_ip_address', '@', '?', '-', '=', '.', '#', '%', '+', '$', '!', '*', ',', '//']\n",
    "cat_features = ['tld']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50039393",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "832cfe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a pipeline transformer for encoding categorical attributes and normalising numerical attributes\n",
    "pipeline = ColumnTransformer([\n",
    "(\"num\", scaler, num_features),\n",
    "(\"cat\", enc, cat_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "53abc3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'pipeline_model.sav'\n",
    "pickle.dump(pipeline, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed8fd4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('urldata.csv').drop(['Unnamed: 0'], axis=1)\n",
    "y = urldata['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b5f56bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url_len</th>\n",
       "      <th>@</th>\n",
       "      <th>?</th>\n",
       "      <th>-</th>\n",
       "      <th>=</th>\n",
       "      <th>.</th>\n",
       "      <th>#</th>\n",
       "      <th>%</th>\n",
       "      <th>+</th>\n",
       "      <th>$</th>\n",
       "      <th>...</th>\n",
       "      <th>digits</th>\n",
       "      <th>letters</th>\n",
       "      <th>Shortining_Service</th>\n",
       "      <th>having_ip_address</th>\n",
       "      <th>tld</th>\n",
       "      <th>len_subdomain</th>\n",
       "      <th>is_subdomain</th>\n",
       "      <th>ratioUrlDomLen</th>\n",
       "      <th>count_spl</th>\n",
       "      <th>ratioSpltinurl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>com.br</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3</td>\n",
       "      <td>0.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>2</td>\n",
       "      <td>0.057143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>org</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>2</td>\n",
       "      <td>0.064516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>be</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>9</td>\n",
       "      <td>0.102273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>235</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>net</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>8</td>\n",
       "      <td>0.034043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   url_len  @  ?  -  =  .  #  %  +  $  ...  digits  letters  \\\n",
       "0       16  0  0  1  0  2  0  0  0  0  ...       0       13   \n",
       "1       35  0  0  0  0  2  0  0  0  0  ...       1       29   \n",
       "2       31  0  0  0  0  2  0  0  0  0  ...       1       25   \n",
       "3       88  0  1  1  4  2  0  0  0  0  ...       7       60   \n",
       "4      235  0  1  1  3  2  0  0  0  0  ...      22      199   \n",
       "\n",
       "   Shortining_Service  having_ip_address     tld  len_subdomain  is_subdomain  \\\n",
       "0                   0                  0  com.br              0             0   \n",
       "1                   0                  0     com              0             0   \n",
       "2                   0                  0     org              0             0   \n",
       "3                   0                  0      be              0             0   \n",
       "4                   0                  0     net              0             0   \n",
       "\n",
       "   ratioUrlDomLen  count_spl ratioSpltinurl  \n",
       "0        0.000015          3       0.187500  \n",
       "1        0.000032          2       0.057143  \n",
       "2        0.000028          2       0.064516  \n",
       "3        0.000081          9       0.102273  \n",
       "4        0.000216          8       0.034043  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1c498e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trans = pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8d0da0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_trans,y,test_size=0.2,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e91491a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94    154732\n",
      "           1       0.93      0.73      0.82     63314\n",
      "\n",
      "    accuracy                           0.91    218046\n",
      "   macro avg       0.92      0.85      0.88    218046\n",
      "weighted avg       0.91      0.91      0.90    218046\n",
      "\n",
      "Confusion Matrix: [[151411   3321]\n",
      " [ 17115  46199]]\n",
      "AUC: 0.938612920110172\n"
     ]
    }
   ],
   "source": [
    "adaB_lexical = AdaBoostClassifier()\n",
    "adaB_lexical.fit(X_train,y_train)\n",
    "y_pred = adaB_lexical.predict(X_test)\n",
    "y_prob = adaB_lexical.predict_proba(X_test)[:,1]\n",
    "print(classification_report(y_test,y_pred))\n",
    "print('Confusion Matrix:',confusion_matrix(y_test, y_pred))\n",
    " \n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('AUC:', roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "847be28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'adaB_lexical_model.sav'\n",
    "pickle.dump(adaB_lexical, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aaa716e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98    154732\n",
      "           1       0.97      0.94      0.95     63314\n",
      "\n",
      "    accuracy                           0.97    218046\n",
      "   macro avg       0.97      0.96      0.97    218046\n",
      "weighted avg       0.97      0.97      0.97    218046\n",
      "\n",
      "Confusion Matrix: [[153036   1696]\n",
      " [  3928  59386]]\n",
      "AUC: 0.9932557599970762\n"
     ]
    }
   ],
   "source": [
    "xgb_lexical= xgb.XGBClassifier(n_estimators= 1000)\n",
    "xgb_lexical.fit(X_train,y_train)\n",
    "y_pred = xgb_lexical.predict(X_test)\n",
    "y_prob = xgb_lexical.predict_proba(X_test)[:,1]\n",
    "print(classification_report(y_test,y_pred))\n",
    "print('Confusion Matrix:',confusion_matrix(y_test, y_pred))\n",
    " \n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('AUC:', roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "def22d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'xgB_lexical_model.sav'\n",
    "pickle.dump(xgb_lexical, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22dfabb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.99      0.85    154732\n",
      "           1       0.90      0.14      0.24     63314\n",
      "\n",
      "    accuracy                           0.75    218046\n",
      "   macro avg       0.82      0.57      0.54    218046\n",
      "weighted avg       0.79      0.75      0.67    218046\n",
      "\n",
      "Confusion Matrix: [[153798    934]\n",
      " [ 54653   8661]]\n",
      "AUC: 0.5666566052669362\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb_lexical= GaussianNB()\n",
    "gnb_lexical.fit(X_train.toarray(),y_train)\n",
    "y_pred = gnb_lexical.predict(X_test.toarray())\n",
    "y_prob = gnb_lexical.predict_proba(X_test.toarray())[:,1]\n",
    "print(classification_report(y_test,y_pred))\n",
    "print('Confusion Matrix:',confusion_matrix(y_test, y_pred))\n",
    " \n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('AUC:', roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c24d7263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98    154732\n",
      "           1       0.97      0.94      0.95     63314\n",
      "\n",
      "    accuracy                           0.97    218046\n",
      "   macro avg       0.97      0.96      0.97    218046\n",
      "weighted avg       0.97      0.97      0.97    218046\n",
      "\n",
      "Confusion Matrix: [[152713   2019]\n",
      " [  3983  59331]]\n",
      "AUC: 0.9912904458741468\n"
     ]
    }
   ],
   "source": [
    "rf_lexical =  RandomForestClassifier(n_estimators=100)\n",
    "rf_lexical.fit(X_train,y_train)\n",
    "y_pred = rf_lexical.predict(X_test)\n",
    "y_prob = rf_lexical.predict_proba(X_test)[:,1]\n",
    "print(classification_report(y_test,y_pred))\n",
    "print('Confusion Matrix:',confusion_matrix(y_test, y_pred))\n",
    " \n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('AUC:', roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "89a5d241",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'rf_lexical_model.sav'\n",
    "pickle.dump(rf_lexical, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c066b404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94    154732\n",
      "           1       0.95      0.75      0.84     63314\n",
      "\n",
      "    accuracy                           0.92    218046\n",
      "   macro avg       0.93      0.87      0.89    218046\n",
      "weighted avg       0.92      0.92      0.91    218046\n",
      "\n",
      "Confusion Matrix: [[152083   2649]\n",
      " [ 15527  47787]]\n",
      "AUC: 0.9450875039531976\n"
     ]
    }
   ],
   "source": [
    "svm_lexical = svm.SVC(probability=True)\n",
    "svm_lexical.fit(X_train, y_train)\n",
    "\n",
    "#Predict y value for test dataset\n",
    "y_predict = svm_lexical.predict(X_test)\n",
    "y_prob = svm_lexical.predict_proba(X_test)[:,1]\n",
    "print(classification_report(y_test,y_predict))\n",
    "print('Confusion Matrix:',confusion_matrix(y_test, y_predict))\n",
    " \n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('AUC:', roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f2022319",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'svm_lexical_model.sav'\n",
    "pickle.dump(svm_lexical, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdad4c72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
